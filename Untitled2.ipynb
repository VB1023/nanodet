{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094dae26-ec38-4c28-b585-91c829372a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parul/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3793/2878403874.py\", line 9, in <module>\n",
      "    from nanodet.model.arch import build_model\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/model/arch/__init__.py\", line 18, in <module>\n",
      "    from .nanodet_plus import NanoDetPlus\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/model/arch/nanodet_plus.py\", line 19, in <module>\n",
      "    from ..head import build_head\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/model/head/__init__.py\", line 3, in <module>\n",
      "    from .gfl_head import GFLHead\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/model/head/gfl_head.py\", line 10, in <module>\n",
      "    from nanodet.util import (\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/util/__init__.py\", line 2, in <module>\n",
      "    from .check_point import (\n",
      "  File \"/home/parul/Desktop/VInit/nanodet/nanodet/util/check_point.py\", line 18, in <module>\n",
      "    import pytorch_lightning as pl\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/__init__.py\", line 35, in <module>\n",
      "    from pytorch_lightning.callbacks import Callback  # noqa: E402\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/__init__.py\", line 14, in <module>\n",
      "    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/batch_size_finder.py\", line 24, in <module>\n",
      "    from pytorch_lightning.callbacks.callback import Callback\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/callback.py\", line 25, in <module>\n",
      "    from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/__init__.py\", line 23, in <module>\n",
      "    from pytorch_lightning.utilities.imports import (  # noqa: F401\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/imports.py\", line 28, in <module>\n",
      "    _TORCHMETRICS_GREATER_EQUAL_0_11 = compare_version(\"torchmetrics\", operator.ge, \"0.11.0\")  # using new API with task\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/lightning_utilities/core/imports.py\", line 78, in compare_version\n",
      "    pkg = importlib.import_module(package)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/torchmetrics/__init__.py\", line 37, in <module>\n",
      "    from torchmetrics import functional  # noqa: E402\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/torchmetrics/functional/__init__.py\", line 122, in <module>\n",
      "    from torchmetrics.functional.text._deprecated import _bleu_score as bleu_score\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/torchmetrics/functional/text/__init__.py\", line 17, in <module>\n",
      "    from torchmetrics.functional.text.chrf import chrf_score\n",
      "  File \"/home/parul/.local/lib/python3.10/site-packages/torchmetrics/functional/text/chrf.py\", line 32, in <module>\n",
      "    _EPS_SMOOTHING = tensor(1e-16)\n",
      "/home/parul/.local/lib/python3.10/site-packages/torchmetrics/functional/text/chrf.py:32: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  _EPS_SMOOTHING = tensor(1e-16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from nanodet.data.batch_process import stack_batch_img\n",
    "from nanodet.data.collate import naive_collate\n",
    "from nanodet.data.transform import Pipeline\n",
    "from nanodet.model.arch import build_model\n",
    "from nanodet.util import Logger, cfg, load_config, load_model_weight\n",
    "from nanodet.util.path import mkdir\n",
    "\n",
    "image_ext = [\".jpg\", \".jpeg\", \".webp\", \".bmp\", \".png\"]\n",
    "\n",
    "# Define a method to load the config, model, and run inference for image.\n",
    "def run_inference_for_image(config_path, model_path, image_path, save_result=False, save_dir='./demo_results'):\n",
    "    # Load the configuration file\n",
    "    load_config(cfg, config_path)\n",
    "\n",
    "    # Initialize logger (can be a placeholder since we're not using TensorBoard in Jupyter)\n",
    "    logger = Logger(local_rank=0, use_tensorboard=False)\n",
    "\n",
    "    # Initialize the predictor (the model)\n",
    "    predictor = Predictor(cfg, model_path, logger, device=\"cuda:0\")\n",
    "    \n",
    "    # Get the image list (this can be a single image or a folder)\n",
    "    image_names = get_image_list(image_path)\n",
    "    image_names.sort()\n",
    "\n",
    "    # Create a directory to save the results\n",
    "    current_time = time.localtime()\n",
    "    if save_result:\n",
    "        save_folder = os.path.join(save_dir, time.strftime(\"%Y_%m_%d_%H_%M_%S\", current_time))\n",
    "        mkdir(local_rank=0, path=save_folder)\n",
    "\n",
    "    # Process each image\n",
    "    result_images = []\n",
    "    for image_name in image_names:\n",
    "        meta, res = predictor.inference(image_name)\n",
    "        result_image = predictor.visualize(res[0], meta, cfg.class_names, 0.35)\n",
    "\n",
    "        # Save the result image if specified\n",
    "        if save_result:\n",
    "            save_file_name = os.path.join(save_folder, os.path.basename(image_name))\n",
    "            cv2.imwrite(save_file_name, result_image)\n",
    "\n",
    "        # Append the result image to the list to display later\n",
    "        result_images.append(result_image)\n",
    "\n",
    "    return result_images\n",
    "\n",
    "\n",
    "# Define the predictor class (same as before, no changes)\n",
    "class Predictor(object):\n",
    "    def __init__(self, cfg, model_path, logger, device=\"cuda:0\"):\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        model = build_model(cfg.model)\n",
    "        ckpt = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "        load_model_weight(model, ckpt, logger)\n",
    "        if cfg.model.arch.backbone.name == \"RepVGG\":\n",
    "            deploy_config = cfg.model\n",
    "            deploy_config.arch.backbone.update({\"deploy\": True})\n",
    "            deploy_model = build_model(deploy_config)\n",
    "            from nanodet.model.backbone.repvgg import repvgg_det_model_convert\n",
    "\n",
    "            model = repvgg_det_model_convert(model, deploy_model)\n",
    "        self.model = model.to(device).eval()\n",
    "        self.pipeline = Pipeline(cfg.data.val.pipeline, cfg.data.val.keep_ratio)\n",
    "\n",
    "    def inference(self, img):\n",
    "        img_info = {\"id\": 0}\n",
    "        if isinstance(img, str):\n",
    "            img_info[\"file_name\"] = os.path.basename(img)\n",
    "            img = cv2.imread(img)\n",
    "        else:\n",
    "            img_info[\"file_name\"] = None\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "        img_info[\"height\"] = height\n",
    "        img_info[\"width\"] = width\n",
    "        meta = dict(img_info=img_info, raw_img=img, img=img)\n",
    "        meta = self.pipeline(None, meta, self.cfg.data.val.input_size)\n",
    "        meta[\"img\"] = torch.from_numpy(meta[\"img\"].transpose(2, 0, 1)).to(self.device)\n",
    "        meta = naive_collate([meta])\n",
    "        meta[\"img\"] = stack_batch_img(meta[\"img\"], divisible=32)\n",
    "        with torch.no_grad():\n",
    "            results = self.model.inference(meta)\n",
    "        return meta, results\n",
    "\n",
    "    def visualize(self, dets, meta, class_names, score_thres, wait=0):\n",
    "        result_img = self.model.head.show_result(\n",
    "            meta[\"raw_img\"][0], dets, class_names, score_thres=score_thres, show=False\n",
    "        )\n",
    "        return result_img\n",
    "\n",
    "\n",
    "def get_image_list(path):\n",
    "    image_names = []\n",
    "    if os.path.isdir(path):\n",
    "        for maindir, subdir, file_name_list in os.walk(path):\n",
    "            for filename in file_name_list:\n",
    "                apath = os.path.join(maindir, filename)\n",
    "                ext = os.path.splitext(apath)[1]\n",
    "                if ext in image_ext:\n",
    "                    image_names.append(apath)\n",
    "    else:\n",
    "        image_names.append(path)\n",
    "    return image_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d43084-5184-4660-b527-1513dfb43f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./inference_results\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Directory where the processed image will be saved\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Run inference for images (processing the image)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result_images \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference_for_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Display results in the notebook\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mrun_inference_for_image\u001b[0;34m(config_path, model_path, image_path, save_result, save_dir)\u001b[0m\n\u001b[1;32m     37\u001b[0m result_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m image_names:\n\u001b[0;32m---> 39\u001b[0m     meta, res \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     result_image \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mvisualize(res[\u001b[38;5;241m0\u001b[39m], meta, cfg\u001b[38;5;241m.\u001b[39mclass_names, \u001b[38;5;241m0.35\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Save the result image if specified\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 84\u001b[0m, in \u001b[0;36mPredictor.inference\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     82\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(img_info\u001b[38;5;241m=\u001b[39mimg_info, raw_img\u001b[38;5;241m=\u001b[39mimg, img\u001b[38;5;241m=\u001b[39mimg)\n\u001b[1;32m     83\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline(\u001b[38;5;28;01mNone\u001b[39;00m, meta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mval\u001b[38;5;241m.\u001b[39minput_size)\n\u001b[0;32m---> 84\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     85\u001b[0m meta \u001b[38;5;241m=\u001b[39m naive_collate([meta])\n\u001b[1;32m     86\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stack_batch_img(meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m], divisible\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Define paths to your config, model, and image\n",
    "config_path = 'config/nanodet-plus-m_416-yolo.yml'  # Path to your model config file\n",
    "model_path = 'workspace/nanodet-plus-m_416/model_best/model_best.ckpt'  # Path to your trained model weights\n",
    "image_path = 'OBJECT.v8-5.coco-mmdetection/train/IMG-20241204-WA0085_jpg.rf.9666815e241f95864860cd7110996a52.jpg'  # Path to the image you want to process\n",
    "\n",
    "# Optionally, you can specify if you want to save the results\n",
    "save_result = True  # Set to True if you want to save the processed image\n",
    "save_dir = './inference_results'  # Directory where the processed image will be saved\n",
    "\n",
    "# Run inference for images (processing the image)\n",
    "result_images = run_inference_for_image(config_path, model_path, image_path, save_result, save_dir)\n",
    "\n",
    "# Display results in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show the first result image\n",
    "plt.imshow(cv2.cvtColor(result_images[0], cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c1f9a8-b37f-46c4-bb2a-984f4b89ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/parul/anaconda3/envs/nanodet/lib/python3.8/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836eb4e-3e9f-422e-8915-5b3504296716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a420759-a093-41e9-8d09-27dfb264851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "run_inference_for_image(config_path, model_path, image_path, save_result, save_dir)\n",
    "t2=time.time()\n",
    "print('\\n',t2-t1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc5b0a-3a91-4209-81f2-d2dc4323e1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
